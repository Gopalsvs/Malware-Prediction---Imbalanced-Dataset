# %% [code] {"_kg_hide-input":false}
import numpy as np # linear algebra
import pandas as pd 

import matplotlib.pyplot as plt
import seaborn as sns

from scipy import stats
from scipy.stats import norm,skew
from scipy.sparse import hstack

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder as OHE,LabelEncoder,StandardScaler as SS
from sklearn.compose import ColumnTransformer
from sklearn.experimental import enable_iterative_imputer  
from sklearn.impute import IterativeImputer
from sklearn.metrics import roc_auc_score,accuracy_score, precision_score, recall_score, f1_score
from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier
from sklearn.model_selection import train_test_split
'''
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
'''        
#All the features which are either string_categorical or which contains nan's
lab_col = ['ProductName','EngineVersion2','EngineVersion3','AppVersion1','AppVersion2','AppVersion3','AvSigVersion0','AvSigVersion1','AvSigVersion2','RtpStateBitfield','AVProductStatesIdentifier','AVProductsInstalled',
          'AVProductsEnabled','CountryIdentifier','CityIdentifier','OrganizationIdentifier','GeoNameIdentifier','LocaleEnglishNameIdentifier',
          'Platform','Processor','OsVer0','OsVer1','OsVer2','OsVer3','OsBuild','OsSuite','OsPlatformSubRelease','OsBuildLab','SkuEdition','IsProtected','IeVerIdentifier',
          'SmartScreen','Firewall','Census_MDC2FormFactor','Census_OEMNameIdentifier','Census_OEMModelIdentifier',
          'Census_ProcessorCoreCount','Census_ProcessorManufacturerIdentifier','Census_ProcessorModelIdentifier','Census_PrimaryDiskTotalCapacity',
          'Census_PrimaryDiskTypeName','Census_SystemVolumeTotalCapacity','Census_TotalPhysicalRAM','Census_InternalPrimaryDiagonalDisplaySizeInInches',
          'Census_ChassisTypeName','Census_InternalPrimaryDisplayResolutionHorizontal','Census_InternalPrimaryDisplayResolutionVertical','Census_PowerPlatformRoleName',
          'Census_InternalBatteryType','Census_InternalBatteryNumberOfCharges','Census_OSVersion0','Census_OSVersion1','Census_OSVersion2','Census_OSVersion3','Census_OSArchitecture','Census_OSBranch','Census_OSBuildNumber',
          'Census_OSBuildRevision','Census_OSEdition','Census_OSSkuName','Census_OSInstallTypeName','Census_OSInstallLanguageIdentifier','Census_OSUILocaleIdentifier',
          'Census_OSWUAutoUpdateOptionsName','Census_ActivationChannel','Census_GenuineStateName','Census_FlightRing','Census_ThresholdOptIn','Census_IsVirtualDevice',
          'Census_FirmwareManufacturerIdentifier','Census_FirmwareVersionIdentifier','Census_IsAlwaysOnAlwaysConnectedCapable','Wdft_IsGamer','Wdft_RegionIdentifier']

#These are the features which conatins no nan's and no encosing is required
nothing_col = ['IsSxsPassiveMode','HasTpm','Census_HasOpticalDiskDrive','Census_IsPortableOperatingSystem','Census_IsSecureBootEnabled',
              'Census_IsTouchEnabled','Census_IsPenCapable']    
    
    
more_nan_data = []
numerical_columns = [
    #'Census_TotalPhysicalRAM',
    #'Census_InternalPrimaryDisplayResolutionHorizontal',
    #'Census_InternalPrimaryDisplayResolutionVertical',
    'Census_PrimaryDiskTotalCapacity',
    'Census_SystemVolumeTotalCapacity',
    'Census_InternalPrimaryDiagonalDisplaySizeInInches',
    'Census_InternalBatteryNumberOfCharges'
    ]

more_uniquevalued_columns = [
    'PuaMode','Census_IsWIMBootEnabled',
    'IsBeta','Census_IsFlightsDisabled',
    'Census_IsFlightsDisabled','AutoSampleOptIn',
    'Census_IsPortableOperatingSystem','SMode',
    'Census_DeviceFamily','UacLuaenable'
    ]

# These are dict which contains keys and their values that has been used to replace in their respective feature columns while 
# preprocessing the data
trans_col_SmartScreen = {'OFF': 'Off','requireadmin': 'RequireAdmin','on':'On','off':'Off'} 
trans_col_normalise = {'UNKNOWN':np.nan,'Unspecified':np.nan}
trans_col_Census_ChassisTypeName = {'Unknown':np.nan}
trans_col_minus_one_nan = {-1:np.nan}
trans_col_nan = {np.nan : 'NoValue'}
inverse_transform = ['NoValue']

# These are the feature columns that are converted from mb to gb(units conversion)  
mb_gb = ['Census_SystemVolumeTotalCapacity',
         'Census_PrimaryDiskTotalCapacity',
         'Census_TotalPhysicalRAM'
        ]

pixel_mm = ['Census_InternalPrimaryDisplayResolutionHorizontal',
            'Census_InternalPrimaryDisplayResolutionVertical'
           ]
    

def LabelEncode_columns(data,column):
    for col in column:
        flag = 0
        data[col].replace(trans_col_nan,inplace = True) # replacing nan values with Novalue for reference in label encoding.
        elf = LabelEncoder()
        data[col] = data[col].astype('str')
        if ((data[col]=='NoValue').sum() > 0):
            flag =1
        data[col]= elf.fit_transform(data[col].ravel())
        if ( flag == 1 ):
            flag = 0
            nan_value = elf.transform(inverse_transform)[0] #getting the value that nan got while label encoding it.
            data[col] = data[col].astype('int64')
            replace_val = {nan_value:np.nan}                # replacing its value back with nan's
            data[col].replace(replace_val,inplace = True)
    return data 

    
def preprocessing(data,train_df):
    #All binary columns which has unique values as 2 
    binary_columns = [i for i in train_df.columns if train_df[i].nunique() == 2]
    categorical_columns = [i for i in train_df.columns if (i not in numerical_columns) & (i not in binary_columns)]

    #collecting the features which has nan data more than 80%
    for i in train_df.columns:
        if (train_df[i].isnull().sum()/train_df.shape[0])*100 > 80:
            more_nan_data.append(i)

    removable_columns = more_nan_data
    # collecting features that has data with value having very percentage in that feature 
    # As these kind of features won't contribute much to the model these has to be removed 
    # from the data 
    for i in more_uniquevalued_columns:
        if i not in removable_columns:
            removable_columns.append(i)
            
    #finally removing those features that don't contribute much to the model       
    for col in removable_columns:
        data.drop(col,axis = 1,inplace = True)
    
    # These are the features whose data is being replaced with the values corresponding to the key
    data['SmartScreen']                  = data['SmartScreen'].replace(trans_col_SmartScreen)   #categorical
    data['Census_PrimaryDiskTypeName']   = data['Census_PrimaryDiskTypeName'].replace(trans_col_normalise)    #categorical
    data['Census_ChassisTypeName']       = data['Census_ChassisTypeName'].replace(trans_col_Census_ChassisTypeName)    #categorical
    data['Census_PowerPlatformRoleName'] = data['Census_PowerPlatformRoleName'].replace(trans_col_normalise)    #categorical
   
    # These features are getting splitted into four different features.
    # This is a part of understanding whether there is a information gain from these newly 
    # formed feature while using tree based algorithm
    data['Census_OSVersion0'] = data['Census_OSVersion'].apply(lambda x:x.split('.')[0])
    data['Census_OSVersion1'] = data['Census_OSVersion'].apply(lambda x:x.split('.')[1])
    data['Census_OSVersion2'] = data['Census_OSVersion'].apply(lambda x:x.split('.')[2])
    data['Census_OSVersion3'] = data['Census_OSVersion'].apply(lambda x:x.split('.')[3])
    data.drop('Census_OSVersion',axis = 1,inplace = True)
    
    data['OsVer0'] = data['OsVer'].apply(lambda x:x.split('.')[0])
    data['OsVer1'] = data['OsVer'].apply(lambda x:x.split('.')[1])
    data['OsVer2'] = data['OsVer'].apply(lambda x:x.split('.')[2])
    data['OsVer3'] = data['OsVer'].apply(lambda x:x.split('.')[3])
    data.drop('OsVer',axis = 1,inplace = True)
    
    data['EngineVersion0'] = data['EngineVersion'].apply(lambda x:x.split('.')[0])
    data['EngineVersion1'] = data['EngineVersion'].apply(lambda x:x.split('.')[1])
    data['EngineVersion2'] = data['EngineVersion'].apply(lambda x:x.split('.')[2])
    data['EngineVersion3'] = data['EngineVersion'].apply(lambda x:x.split('.')[3])
    data.drop('EngineVersion',axis = 1,inplace = True)
    
    data['AppVersion0'] = data['AppVersion'].apply(lambda x:x.split('.')[0])
    data['AppVersion1'] = data['AppVersion'].apply(lambda x:x.split('.')[1])
    data['AppVersion2'] = data['AppVersion'].apply(lambda x:x.split('.')[2])
    data['AppVersion3'] = data['AppVersion'].apply(lambda x:x.split('.')[3])
    data.drop('AppVersion',axis = 1,inplace = True)
    
    data['AvSigVersion0'] = data['AvSigVersion'].apply(lambda x:x.split('.')[0])
    data['AvSigVersion1'] = data['AvSigVersion'].apply(lambda x:x.split('.')[1])
    data['AvSigVersion2'] = data['AvSigVersion'].apply(lambda x:x.split('.')[2])
    data['AvSigVersion3'] = data['AvSigVersion'].apply(lambda x:x.split('.')[3])
    data.drop('AvSigVersion',axis = 1,inplace = True)
    
    # This feature is getting replaced as 0 or 1 which corresponds to either 'lithuim' or 'non-lithuim'
    # and 2 which ever tha data has nan and later getting replaced back with nan's after replcaing 0 and 1.
    temp   = data['Census_InternalBatteryType'].astype('str')    #categorical
    temp   = temp.apply(lambda x: '1' if x[0]=='l' else( '2' if x[0]=='n' else '0'))
    temp   = temp.astype('int64')
    data['Census_InternalBatteryType']   = temp.replace({2:np.nan})
    
    for col in mb_gb:
        data[col].fillna(-1024, inplace = True)
        #temp = data[col].fillna(-1024,inplace = False)
        data[col] = data[col].apply(lambda x:x/1024).astype('int64')
        data[col] = data[col].replace(trans_col_minus_one_nan)
        
    for col in pixel_mm:
        data[col].fillna(-26, inplace = True)
        #temp = data[col].fillna(-26,inplace = False)
        data[col] = data[col].apply(lambda x:x/26).astype('int64')
        data[col] = data[col].replace(trans_col_minus_one_nan)
        
    # There are more features which has unique value as 1 after getting new features. 
    feature_category = ['AvSigVersion0', 'AvSigVersion1','AvSigVersion2','AvSigVersion3','Census_OSVersion0', 'Census_OSVersion1', 'Census_OSVersion2', 'Census_OSVersion3', 'OsVer0', 'OsVer1', 'OsVer2', 'OsVer3', 'EngineVersion0', 'EngineVersion1', 'EngineVersion2', 'EngineVersion3', 'AppVersion0', 'AppVersion1', 'AppVersion2', 'AppVersion3']
    unique_valued_feature = []
    # Collecting all those features since they don't contribute much to the model.
    for i in feature_category:
        if(data[i].nunique() == 1):
            unique_valued_feature.append(i)
        
    cat_lab_columns = []
    bin_lab_columns = []
    for i in categorical_columns:
        if i not in removable_columns:
            cat_lab_columns.append(i)

    for i in binary_columns:
        if i not in removable_columns:
            bin_lab_columns.append(i)
    # Removing these features since these have been seperated and made into new features.
    dropped_columns = ['Census_OSVersion', 'EngineVersion', 'AppVersion', 'AvSigVersion', 'OsVer']
    # These are the feautures that got added.
    appended_columns = ['AvSigVersion0', 'AvSigVersion1','AvSigVersion2','Census_OSVersion0', 'Census_OSVersion1', 'Census_OSVersion2', 'Census_OSVersion3', 'OsVer0', 'OsVer1', 'OsVer2', 'OsVer3', 'EngineVersion2', 'EngineVersion3', 'AppVersion1', 'AppVersion2', 'AppVersion3']

    for i in dropped_columns:
        cat_lab_columns.remove(i)
    for i in appended_columns:
        cat_lab_columns.append(i)
    
    # label enconding the features
    LabelEncode_columns(data, cat_lab_columns)
    LabelEncode_columns(data, bin_lab_columns)
    
    # Collecting all different types of data which has nan's (binary,categorical,numeric) 
    nan_columns = []
    for i in data.columns:
        if(data[i].isnull().sum() != 0):
            nan_columns.append(i)

    nan_numeric_columns = []
    nan_binary_columns = []
    nan_categorical_columns = []

    for i in nan_columns:
        if i in numerical_columns:
            nan_numeric_columns.append(i)
        elif i in binary_columns:
            nan_binary_columns.append(i)
        elif i in categorical_columns:
            nan_categorical_columns.append(i)

    non_nan_categorical_columns = []
    for i in data.columns:
        if i not in nan_categorical_columns:
            non_nan_categorical_columns.append(i)
            
    # Filling binary columns with mode of that feature column
    for i in nan_binary_columns:
        train_df[i].fillna(train_df[i].mode()[0], inplace=True)
        data[i].fillna(data[i].mode()[0], inplace=True)

    return data

    
def removable_features(X):
    for col in removable_columns:
        X.drop(col,axis = 1,inplace = True)

# These are the metrics used to understand the performance of the model
def metrics(true, preds):
    accuracy = accuracy_score(true, preds)
    recall = recall_score(true, preds)
    precision = precision_score(true, preds)
    f1score = f1_score(true, preds)
    print ('accuracy: {}, recall: {}, precision: {}, f1-score: {}'.format(accuracy, recall, precision, f1score))
    

def model():
    # Splititng data into 80% train and 20% test
    X_train, X_test, Y_train,Y_test = train_test_split(X, Y, test_size = 0.2,random_state=21,stratify = Y)
    # Used AdaboostClassifier model with base parameter as RandomForestClassifier
    ada_boost = AdaBoostClassifier(n_estimators = 10, base_estimator=RandomForestClassifier(n_estimators = 2 ** 8, min_samples_leaf = 2 ** 7, n_jobs=-1, verbose=True))
    ada_boost.fit(X_train, Y_train)
    predictions = ada_boost.predict(X_test)

    ada_boost_probs = ada_boost.predict_proba(X_test)[:,1]
    # Getting score metrics on train data and test data
    metrics(Y_train, ada_boost.predict(X_train))
    print("adaboost train roc_auc_score",roc_auc_score(Y_train, ada_boost.predict_proba(X_train)[:,1]))
    print()
    metrics(Y_test, ada_boost.predict(X_test))
    print("adaboost test roc_auc_score",roc_auc_score(Y_test,ada_boost.predict_proba(X_test)[:,1]))
    

def submission():
    imputed_x_test = num_imputer.transform(total_df[len_rows:])
    # Model that is trained with 100% of the train data is being used to predict the test data for submitting.
    ada_boost2 = AdaBoostClassifier(n_estimators = 10, base_estimator=RandomForestClassifier(n_estimators = 2 ** 8, min_samples_leaf = 2 ** 7, n_jobs=-1, verbose=True))
    ada_boost2.fit(imputed_num,target_data)
    
    metrics(target_data, ada_boost2.predict(imputed_num))
    print("adaboost roc_auc_score",roc_auc_score(target_data, ada_boost2.predict_proba(imputed_num)[:,1]))
    
    predictions = ada_boost2.predict_proba(imputed_x_test)[:,1]
    test_predict = pd.DataFrame(data = predictions , columns = ['HasDetections'])
    submission = pd.concat(( submission, test_predict),axis = 1)
    submission.to_csv('submission_test.csv', index = False )
    
train_df = pd.read_csv("train.csv",encoding = 'utf-8')
test_df  = pd.read_csv("test.csv",encoding = 'utf-8')


submission = test_df['MachineIdentifier']
len_index = train_df.index
len_rows =  len(len_index)
target_data = train_df['HasDetections']
    
train_df.drop(['HasDetections'],axis=1,inplace = True)
total_df = pd.concat([train_df,test_df],axis = 0,ignore_index = True)
    
train_df.drop(['MachineIdentifier'], axis =1, inplace = True) #unique Id
test_df.drop(['MachineIdentifier'], axis =1, inplace = True) #unique Id
total_df.drop(['MachineIdentifier'], axis =1, inplace = True) #unique Id

total_df = preprocessing(total_df,train_df)
print(total_df)
# Used Iterative imputer which is a multivariate model which fills the missing data
# using remaining features available to it. Base estimator is BayesianRidge()
num_imputer = IterativeImputer()
imputed_num = num_imputer.fit_transform(total_df[:len_rows])
X = imputed_num
Y = target_data[:len_rows]
print("imputed")
model()
submission()


